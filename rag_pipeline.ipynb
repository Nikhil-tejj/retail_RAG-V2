{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565c19d0",
   "metadata": {},
   "source": [
    "# Product RAG Pipeline (MongoDB + Pinecone + MiniLM + FLAN-T5)\n",
    "This notebook loads and cleans products.csv, inserts into MongoDB, builds MiniLM embeddings and upserts to Pinecone, then performs RAG search with price filters and generates a natural language answer using FLAN-T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b82904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas pymongo python-dotenv certifi sentence-transformers pinecone transformers torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81a6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikhil\\Downloads\\New folder\\myvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os, re, json\n",
    "from dotenv import load_dotenv\n",
    "import certifi\n",
    "from pymongo import MongoClient, ASCENDING, errors\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MONGO_URI = os.getenv('ATLAS_URI')\n",
    "if not MONGO_URI:\n",
    "    raise RuntimeError('Missing ATLAS_URI in environment (.env)')\n",
    "mongo_client = MongoClient(MONGO_URI, tlsCAFile=certifi.where())\n",
    "db = mongo_client['ecommerce_db']\n",
    "products_coll = db['products']\n",
    "\n",
    "try:\n",
    "    products_coll.create_index([('unique_id', ASCENDING)], unique=True, background=True)\n",
    "    products_coll.create_index([('category', ASCENDING)], background=True)\n",
    "    products_coll.create_index([('price', ASCENDING)], background=True)\n",
    "except errors.PyMongoError as e:\n",
    "    print('Index setup warning:', e)\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "PINECONE_API_KEY = os.getenv('Pinecone_API_KEY')\n",
    "if not PINECONE_API_KEY:\n",
    "    raise RuntimeError('Missing Pinecone_API_KEY in environment (.env)')\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = 'prod-search'\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(name=INDEX_NAME, dimension=384, metric='cosine', spec=ServerlessSpec(cloud='aws', region='us-east-1'))\n",
    "pinecone_index = pc.Index(INDEX_NAME)\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64618134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting to Mongo: 100%|██████████| 5196/5196 [02:53<00:00, 29.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted/updated 5196 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_price(value):\n",
    "    if pd.isna(value):\n",
    "        return 0.0\n",
    "    s = str(value)\n",
    "    s = re.sub(r'[^\\d.,]', '', s).replace(',', '')\n",
    "    try:\n",
    "        return float(s) if s else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def clean_and_insert(csv_path='prod.csv'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    rename = {\n",
    "        'Uniq Id': 'unique_id',\n",
    "        'Product Title': 'title',\n",
    "        'Product Description': 'description',\n",
    "        'Brand': 'brand',\n",
    "        'Price': 'price',\n",
    "        'Image Urls': 'image_urls',\n",
    "        'Category': 'category',\n",
    "    }\n",
    "    df = df.rename(columns=rename)\n",
    "\n",
    "    df['title'] = df['title'].astype(str).str.strip()\n",
    "    df['description'] = df.get('description', '').fillna('').astype(str).str.strip()\n",
    "    df['brand'] = df.get('brand', '').astype(str).str.strip()\n",
    "    df['category'] = df.get('category', '').astype(str).str.strip()\n",
    "    df['image_urls'] = df.get('image_urls', '').fillna('')\n",
    "    df['price'] = df['price'].apply(clean_price).astype(float)\n",
    "\n",
    "    df = df.dropna(subset=['unique_id'])\n",
    "    df['unique_id'] = df['unique_id'].astype(str)\n",
    "    df = df.drop_duplicates(subset=['unique_id'])\n",
    "\n",
    "    df['image_urls'] = df['image_urls'].apply(lambda x: str(x).split('|') if str(x) else [])\n",
    "\n",
    "    upserts = 0\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc='Upserting to Mongo'):\n",
    "        doc = {\n",
    "            'unique_id': row['unique_id'],\n",
    "            'title': row['title'],\n",
    "            'description': row['description'],\n",
    "            'brand': row['brand'],\n",
    "            'price': float(row['price']),\n",
    "            'category': row['category'],\n",
    "            'image_urls': row['image_urls'],\n",
    "        }\n",
    "        res = products_coll.update_one({'unique_id': row['unique_id']}, {'$set': doc}, upsert=True)\n",
    "        if res.upserted_id is not None or res.modified_count > 0:\n",
    "            upserts += 1\n",
    "    print(f'✅ Upserted/updated {upserts} documents.')\n",
    "\n",
    "clean_and_insert('prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbee3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding + upsert: 5196it [09:36,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted 5196 vectors into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "def upsert_embeddings_to_pinecone(batch_size=100):\n",
    "    cursor = products_coll.find({}, {'unique_id': 1, 'title': 1, 'description': 1, 'price': 1, 'brand': 1})\n",
    "    batch, total = [], 0\n",
    "    for doc in tqdm(cursor, desc='Embedding + upsert'):\n",
    "        uid = str(doc['unique_id'])\n",
    "        text = f\"{doc.get('title','')} [SEP] {doc.get('description','')}\".strip()\n",
    "        emb = embed_model.encode(text).tolist()\n",
    "        meta = {\n",
    "            'price': float(doc.get('price', 0.0)),\n",
    "            'brand': str(doc.get('brand', ''))\n",
    "        }\n",
    "        batch.append({'id': uid, 'values': emb, 'metadata': meta})\n",
    "        if len(batch) >= batch_size:\n",
    "            pinecone_index.upsert(batch)\n",
    "            total += len(batch)\n",
    "            batch = []\n",
    "    if batch:\n",
    "        pinecone_index.upsert(batch)\n",
    "        total += len(batch)\n",
    "    print(f'✅ Upserted {total} vectors into Pinecone.')\n",
    "\n",
    "upsert_embeddings_to_pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529cd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price_filter(query: str):\n",
    "    \"\"\"\n",
    "    Parse price filters from query. Supports:\n",
    "    - Lower bounds: 'under 100', 'below 100', 'less than 100', 'under100'\n",
    "    - Upper bounds: 'above 500', 'over 500', 'more than 500', 'above500'\n",
    "    - Range: 'between 100 and 500', '100 to 500'\n",
    "    Returns: dict with 'min_price' and/or 'max_price' keys\n",
    "    \"\"\"\n",
    "    price_filter = {}\n",
    "    \n",
    "    lower_patterns = [\n",
    "        r'(under|below|less\\s*than)\\s*[₹$]?\\s*(\\d+)',\n",
    "        r'under\\s*(\\d+)',\n",
    "        r'below\\s*(\\d+)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in lower_patterns:\n",
    "        m = re.search(pattern, query, flags=re.I)\n",
    "        if m:\n",
    "            try:\n",
    "                price = float([g for g in m.groups() if g and g.isdigit()][-1])\n",
    "                price_filter['max_price'] = price\n",
    "                break\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    upper_patterns = [\n",
    "        r'(above|over|more\\s*than|greater\\s*than)\\s*[₹$]?\\s*(\\d+)',\n",
    "        r'above\\s*(\\d+)',\n",
    "        r'over\\s*(\\d+)',\n",
    "        r'minimum\\s*[₹$]?\\s*(\\d+)',\n",
    "        r'at\\s*least\\s*[₹$]?\\s*(\\d+)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in upper_patterns:\n",
    "        m = re.search(pattern, query, flags=re.I)\n",
    "        if m:\n",
    "            try:\n",
    "                price = float([g for g in m.groups() if g and g.isdigit()][-1])\n",
    "                price_filter['min_price'] = price\n",
    "                break\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    range_patterns = [\n",
    "        r'between\\s*[₹$]?\\s*(\\d+)\\s*(?:and|to|-)\\s*[₹$]?\\s*(\\d+)',\n",
    "        r'(\\d+)\\s*(?:to|-)\\s*(\\d+)',\n",
    "        r'from\\s*[₹$]?\\s*(\\d+)\\s*(?:to|-)\\s*[₹$]?\\s*(\\d+)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in range_patterns:\n",
    "        m = re.search(pattern, query, flags=re.I)\n",
    "        if m:\n",
    "            try:\n",
    "                min_price = float(m.group(1))\n",
    "                max_price = float(m.group(2))\n",
    "                if min_price <= max_price:\n",
    "                    price_filter['min_price'] = min_price\n",
    "                    price_filter['max_price'] = max_price\n",
    "                else:\n",
    "                    price_filter['min_price'] = max_price\n",
    "                    price_filter['max_price'] = min_price\n",
    "                break\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    return price_filter if price_filter else None\n",
    "\n",
    "def search_products(query: str, top_k: int = 10):\n",
    "    q_emb = embed_model.encode(query).tolist()\n",
    "    res = pinecone_index.query(vector=q_emb, top_k=top_k, include_metadata=True)\n",
    "    matches = res.get('matches', [])\n",
    "    if not matches:\n",
    "        return {'status': 'not_found', 'message': 'No vector matches.'}\n",
    "\n",
    "    ids = [m['id'] for m in matches]\n",
    "    price_filter = parse_price_filter(query)\n",
    "\n",
    "    mongo_filter = {'unique_id': {'$in': ids}}\n",
    "    if price_filter:\n",
    "        price_query = {}\n",
    "        if 'min_price' in price_filter:\n",
    "            price_query['$gte'] = price_filter['min_price']\n",
    "        if 'max_price' in price_filter:\n",
    "            price_query['$lte'] = price_filter['max_price']\n",
    "        if price_query:\n",
    "            mongo_filter['price'] = price_query\n",
    "    \n",
    "    docs = list(products_coll.find(mongo_filter))\n",
    "    if not docs:\n",
    "        filter_msg = \"\"\n",
    "        if price_filter:\n",
    "            if 'min_price' in price_filter and 'max_price' in price_filter:\n",
    "                filter_msg = f\" with price between ₹{price_filter['min_price']} and ₹{price_filter['max_price']}\"\n",
    "            elif 'min_price' in price_filter:\n",
    "                filter_msg = f\" with price above ₹{price_filter['min_price']}\"\n",
    "            elif 'max_price' in price_filter:\n",
    "                filter_msg = f\" with price under ₹{price_filter['max_price']}\"\n",
    "        return {'status': 'not_found', 'message': f'No products matched after filtering{filter_msg}.'}\n",
    "\n",
    "    score_map = {m['id']: m.get('score', 0) for m in matches}\n",
    "    docs.sort(key=lambda d: score_map.get(str(d.get('unique_id')), 0), reverse=True)\n",
    "    \n",
    "    result = {'status': 'success', 'results': docs}\n",
    "    if price_filter:\n",
    "        result['price_filter'] = price_filter\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55995e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gen = pipeline('text2text-generation', model='google/flan-t5-small')\n",
    "\n",
    "def generate_response(query: str, products: list):\n",
    "    if not products:\n",
    "        return 'I could not find matching products right now.'\n",
    "    \n",
    "    top = products[:3] \n",
    "    brands = list({str(p.get('brand','')).strip() for p in top if p.get('brand') and str(p.get('brand','')).strip()})\n",
    "    pr = [float(p.get('price', 0)) for p in top if isinstance(p.get('price', 0), (int, float)) and p.get('price', 0) > 0]\n",
    "    pr_min = min(pr) if pr else None\n",
    "    pr_max = max(pr) if pr else None\n",
    "    \n",
    "    product_info = []\n",
    "    for i, p in enumerate(top, 1):\n",
    "        title = str(p.get('title', 'Product')).strip()\n",
    "        if len(title) > 50:\n",
    "            title = title[:47] + \"...\"\n",
    "        brand = str(p.get('brand', 'Unknown')).strip()\n",
    "        price = p.get('price', 0)\n",
    "        product_info.append(f\"{i}. {title} by {brand} (₹{price})\")\n",
    "    \n",
    "    brand_text = f\"from brands like {', '.join(brands[:2])}\" if brands else \"\"\n",
    "    price_text = \"\"\n",
    "    if pr_min and pr_max:\n",
    "        if pr_min == pr_max:\n",
    "            price_text = f\"priced at ₹{pr_min}\"\n",
    "        else:\n",
    "            price_text = f\"ranging from ₹{pr_min} to ₹{pr_max}\"\n",
    "    \n",
    "    prompt = f\"\"\"Write a helpful product recommendation response.And try to convince the user\n",
    "Write 2-3 sentences explaining why these are good matches {brand_text} {price_text}.\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = gen(\n",
    "            prompt, \n",
    "            max_new_tokens=80, \n",
    "            do_sample=True,\n",
    "            num_beams=3,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=gen.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        response = result[0]['generated_text'].strip()\n",
    "        \n",
    "        if response:\n",
    "            sentences = response.split('.')\n",
    "            unique_sentences = []\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence.strip()\n",
    "                if sentence and sentence not in unique_sentences:\n",
    "                    unique_sentences.append(sentence)\n",
    "            response = '. '.join(unique_sentences[:3]) \n",
    "            if response and not response.endswith('.'):\n",
    "                response += '.'\n",
    "        \n",
    "        return response if response else f\"I found {len(products)} relevant products for your search.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Generation error: {e}\")\n",
    "        brand_mention = f\" from {brands[0]}\" if brands else \"\"\n",
    "        price_mention = f\" under ₹{pr_max}\" if pr_max else \"\"\n",
    "        return f\"I found {len(products)} great products matching your search{brand_mention}{price_mention}. These options should meet your needs perfectly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddf76df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 'premium shampoo above 500'\n",
      "============================================================\n",
      "Found 4 products\n",
      "Price filter applied: min: ₹500.0\n",
      "\n",
      "Top 3 results:\n",
      "1. Scentio Hair Professional Argan Oil Therapy Shampoo, 500 ml\n",
      "   Brand: SCENTIO | Price: ₹819.0\n",
      "2. Deptrol Car Wash Shampoo 500 ml Pack of 24\n",
      "   Brand: Deptrol | Price: ₹3146.0\n",
      "3. Peter Thomas Roth Mega-Rich Shampoo 8.5 fl oz.\n",
      "   Brand: Peter | Price: ₹3344.0\n",
      "\n",
      "Response :\n",
      "SCENTIO is a brand that has been rated PG-13. It is a good match for SCENTIO. It is rated PG-13.\n",
      "\n",
      "Testing: 'moisturizer between 200 and 800'\n",
      "============================================================\n",
      "Found 1 products\n",
      "Price filter applied: min: ₹200.0, max: ₹800.0\n",
      "\n",
      "Top 3 results:\n",
      "1. Jergens Dry Skin Moisturiser (600ml)\n",
      "   Brand: Jergens | Price: ₹715.0\n",
      "\n",
      "Response :\n",
      "135715.\n",
      "\n",
      "Testing: 'organic products over 300'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 products\n",
      "Price filter applied: min: ₹300.0\n",
      "\n",
      "Top 3 results:\n",
      "1. Adi Naturals Organic Tamarind - 500 GMS Pack of 3\n",
      "   Brand: Adi Naturals | Price: ₹390.0\n",
      "2. Tates The Natural Miracle Conditioner 100% Organic 16 Oz.\n",
      "   Brand: Tates | Price: ₹3240.0\n",
      "\n",
      "Response :\n",
      "It's a bit pricey, but it's worth the money.\n",
      "\n",
      "Testing: 'longlasting french aroma perfume'\n",
      "============================================================\n",
      "Found 10 products\n",
      "\n",
      "Top 3 results:\n",
      "1. Remy Marquis (Paris) Pour Femme Eau De Parfum, 100ml\n",
      "   Brand: Remy Marquis | Price: ₹1110.0\n",
      "2. Adf - Anais De France Floral Beauty Perfume For Women\n",
      "   Brand: ADF - ANAIS DE FRANCE | Price: ₹210.0\n",
      "3. Verser Golden Oudh Attar Pure Natural Roll on Long Lasting Fragrance Perfume for Men & Women (Non-alcoholic)\n",
      "   Brand: Verser | Price: ₹2800.0\n",
      "\n",
      "Response :\n",
      "ANAIS DE FRANCE is a brand that has a high percentage of sales.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_queries = [\n",
    "    'premium shampoo above 500',\n",
    "    'moisturizer between 200 and 800',\n",
    "    'organic products over 300',\n",
    "    'longlasting french aroma perfume'\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nTesting: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    res = search_products(query, top_k=10)\n",
    "    if res.get('status') == 'success':\n",
    "        prods = res['results']\n",
    "        price_filter = res.get('price_filter', {})\n",
    "        \n",
    "        print(f'Found {len(prods)} products')\n",
    "        if price_filter:\n",
    "            filter_desc = []\n",
    "            if 'min_price' in price_filter:\n",
    "                filter_desc.append(f\"min: ₹{price_filter['min_price']}\")\n",
    "            if 'max_price' in price_filter:\n",
    "                filter_desc.append(f\"max: ₹{price_filter['max_price']}\")\n",
    "            print(f'Price filter applied: {\", \".join(filter_desc)}')\n",
    "\n",
    "        print('\\nTop 3 results:')\n",
    "        for i, p in enumerate(prods[:3], 1):\n",
    "            print(f'{i}. {p.get(\"title\", \"N/A\")}')\n",
    "            print(f'   Brand: {p.get(\"brand\", \"N/A\")} | Price: ₹{p.get(\"price\", 0)}')\n",
    "\n",
    "        print('\\nResponse :')\n",
    "        print(generate_response(query,prods))\n",
    "    else:\n",
    "        print(f'{res.get(\"message\", \"No results found\")}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f30cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
